{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53835f56-5acd-4868-9a84-844ecd4179a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([7,8,9])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7f4992-d877-488c-8a58-42c663c2b280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tf.constant(7)\n",
    "scalar\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f55d1-d03f-415c-88b0-990e67cfb09a",
   "metadata": {},
   "source": [
    "A scalar is known as a rank 0 tensor. Because it has no dimensions (it's just a number).\n",
    "\n",
    "ðŸ”‘ Note: For now, you don't need to know too much about the different ranks of tensors (but we will see more on this later). The important point is knowing tensors can have an unlimited range of dimensions (the exact amount will depend on what data you're representing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7e17c-45f3-4747-aa37-f233546b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the number of dimensions of a tensor (ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defc2851-382c-428b-bb13-cfe906953c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create another matrix and define the datatype\n",
    "another_matrix = tf.constant([[10., 7.],\n",
    "                              [3., 2.],\n",
    "                              [8., 9.]], dtype=tf.float16) # specify the datatype with 'dtype'\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ed40ac-263f-4367-9c71-9c34a38324b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# How about a tensor? (more than 2 dimensions, although, all of the above items are also technically tensors)\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                       [4, 5, 6]],\n",
    "                      [[7, 8, 9],\n",
    "                       [10, 11, 12]],\n",
    "                      [[13, 14, 15],\n",
    "                       [16, 17, 18]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafada5-df20-42fa-855a-66af8d92683f",
   "metadata": {},
   "source": [
    "Creating random tensors\n",
    "Random tensors are tensors of some abitrary size which contain random numbers.\n",
    "\n",
    "Why would you want to create random tensors?\n",
    "\n",
    "This is what neural networks use to intialize their weights (patterns) that they're trying to learn in the data.\n",
    "\n",
    "For example, the process of a neural network learning often involves taking a random n-dimensional array of numbers and refining them until they represent some kind of pattern (a compressed way to represent the original data).\n",
    "\n",
    "How a network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2aa498b-80c5-48d4-a2ac-bd79700fda3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random (but the same) tensors\n",
    "random_1 = tf.random.Generator.from_seed(42) # set the seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3, 2)) # create tensor from a normal distribution \n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# Are they equal?\n",
    "random_1, random_2, random_1 == random_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aed7b22-504e-476f-8c0c-31a66ba22d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[ 0.27305737, -0.29925638],\n",
       "        [-0.3652325 ,  0.61883307],\n",
       "        [-1.0130816 ,  0.28291714]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[False, False],\n",
       "        [False, False],\n",
       "        [False, False]])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create two random (and different) tensors\n",
    "random_3 = tf.random.Generator.from_seed(42)\n",
    "random_3 = random_3.normal(shape=(3, 2))\n",
    "random_4 = tf.random.Generator.from_seed(11)\n",
    "random_4 = random_4.normal(shape=(3, 2))\n",
    "\n",
    "# Check the tensors and see if they are equal\n",
    "random_3, random_4, random_1 == random_3, random_3 == random_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3111e-887e-4b34-98ab-6b2f58faf509",
   "metadata": {},
   "source": [
    "What if you wanted to shuffle the order of a tensor?\n",
    "\n",
    "Wait, why would you want to do that?\n",
    "\n",
    "Let's say you working with 15,000 images of cats and dogs and the first 10,000 images of were of cats and the next 5,000 were of dogs. This order could effect how a neural network learns (it may overfit by learning the order of the data), instead, it might be a good idea to move your data around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8e7156-259c-4373-9340-138b8fd8d094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 2,  5],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Shuffle a tensor (valuable for when you want to shuffle your data)\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                            [3, 4],\n",
    "                            [2, 5]])\n",
    "# Gets different results each time\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e865a6d8-0834-4fbd-98f2-654af2881954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Shuffle in the same order every time using the seed parameter (won't acutally be the same)\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a2d92-b84c-4127-8b77-40244f438a59",
   "metadata": {},
   "source": [
    "Wait... why didn't the numbers come out the same?\n",
    "\n",
    "It's due to rule #4 of the tf.random.set_seed() documentation.\n",
    "\n",
    "\"4. If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence.\"\n",
    "\n",
    "tf.random.set_seed(42) sets the global seed, and the seed parameter in tf.random.shuffle(seed=42) sets the operation seed.\n",
    "\n",
    "Because, \"Operations that rely on a random seed actually derive it from two seeds: the global and operation-level seeds. This sets the global seed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c4ebc91-1d83-47cc-8ecf-f64165ce7b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Shuffle in the same order every time\n",
    "\n",
    "# Set the global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae71919-5c80-4b56-acef-a641f4d35cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'not_shuffled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m) \u001b[38;5;66;03m# if you comment this out you'll get different results\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set the operation random seed\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[43mnot_shuffled\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'not_shuffled' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the global random seed\n",
    "tf.random.set_seed(42) # if you comment this out you'll get different results\n",
    "\n",
    "# Set the operation random seed\n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa7312-62df-4a3a-b11c-2cc3653e89a2",
   "metadata": {},
   "source": [
    "Other ways to make tensors\n",
    "Though you might rarely use these (remember, many tensor operations are done behind the scenes for you), you can use tf.ones() to create a tensor of all ones and tf.zeros() to create a tensor of all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dfaea1c-0381-4024-87a6-888bb612910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5c016-23bb-4f1b-a3e3-30481b7323de",
   "metadata": {},
   "source": [
    "You can also turn NumPy arrays in into tensors.\n",
    "\n",
    "Remember, the main difference between tensors and NumPy arrays is that tensors can be run on GPUs.\n",
    "\n",
    "ðŸ”‘ Note: A matrix or tensor is typically represented by a capital letter (e.g. X or A) where as a vector is typically represented by a lowercase letter (e.g. y or b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f72cb7-714b-4c18-8044-4e2f5d5fa978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24]),\n",
       " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15],\n",
       "         [16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24]]])>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32) # create a NumPy array between 1 and 25\n",
    "A = tf.constant(numpy_A,  \n",
    "                shape=[2, 4, 3]) # note: the shape total (2*4*3) has to match the number of elements in the array\n",
    "numpy_A, A\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8325c-f03e-4fdb-a30c-7a29d31fbf75",
   "metadata": {},
   "source": [
    "Getting information from tensors (shape, rank, size)\n",
    "There will be times when you'll want to get different pieces of information from your tensors, in particuluar, you should know the following tensor vocabulary:\n",
    "\n",
    "Shape: The length (number of elements) of each of the dimensions \n",
    "of a tensor.\n",
    "Rank: The number of tensor dimensions. A scalar has rank 0, a vector has rank 1, a matrix is rank 2, a tensor has rank n.\n",
    "Axis or Dimension: A particular dimension of a tensor.\n",
    "Size: The total number of items in the tensor.\n",
    "You'll use these especially when you're trying to line up the shapes of your data to the shapes of your model. For example, making sure the shape of your image tensors are the same shape as your models input layer.\n",
    "\n",
    "We've already seen one of these before using the ndim attribute. Let's see the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf1bfa39-543a-461c-bc4b-f8172182958f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a rank 4 tensor (4 dimensions)\n",
    "rank_4_tensor = tf.zeros([2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6cf9e86-e9e4-433e-a7a7-77c64a817fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85abc329-a83d-4555-81e3-1c894218bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "Elements along axis 0 of tensor: 2\n",
      "Elements along last axis of tensor: 5\n",
      "Total number of elements (2*3*4*5): 120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get various attributes of tensor\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (2*3*4*5):\", tf.size(rank_4_tensor).numpy()) # .numpy() converts to NumPy array\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8773d495-9d48-42e2-848f-5ed66e2426dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the first 2 items of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b83c9e11-ae81-418c-b7f2-c3da29b1632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the dimension from each index except for the final one\n",
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef3dcb8a-e920-448b-be46-4d4d13fd5986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                             [3, 4]])\n",
    "\n",
    "# Get the last item of each row\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735408a5-4eec-4f7b-b798-e631f77c0519",
   "metadata": {},
   "source": [
    " # Matrix mutliplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee212313-450c-427b-9a08-6c83a8e82f36",
   "metadata": {},
   "source": [
    "One of the most common operations in machine learning algorithms is matrix multiplication.\n",
    "\n",
    "TensorFlow implements this matrix multiplication functionality in the tf.matmul() method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "The inner dimensions must match:\n",
    "(3, 5) @ (3, 5) won't work\n",
    "(5, 3) @ (3, 5) will work\n",
    "(3, 5) @ (5, 3) will work\n",
    "The resulting matrix has the shape of the outer dimensions:\n",
    "(5, 3) @ (3, 5) -> (5, 5)\n",
    "(3, 5) @ (5, 3) -> (3, 3)\n",
    "ðŸ”‘ Note: '@' in Python is the symbol for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980801e1-1a42-4694-abde-a91151af2d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[87, 78],\n",
       "       [62, 62],\n",
       "       [39, 62]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mat1= tf.constant([[6,9,0],\n",
    "                   [4,6,2],\n",
    "                   [1,5,7]])\n",
    "mat2 =  tf.constant([[10, 7],\n",
    "                     [3, 4],\n",
    "                     [2, 5]])\n",
    "mat1@mat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a6c083-d794-40c1-ab47-5adf91be9678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[6, 4, 1],\n",
       "       [9, 6, 5],\n",
       "       [0, 2, 7]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b044e-cdcd-4587-8712-3c1167a238ec",
   "metadata": {},
   "source": [
    "# Changing the datatype of a tensor\n",
    "Sometimes you'll want to alter the default datatype of your tensor.\n",
    "\n",
    "This is common when you want to compute using less precision (e.g. 16-bit floating point numbers vs. 32-bit floating point numbers).\n",
    "\n",
    "Computing with less precision is useful on devices with less computing capacity such as mobile devices (because the less bits, the less space the computations require).\n",
    "\n",
    "You can change the datatype of a tensor using tf.cast()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6155cec3-773a-496b-927f-71a8790190ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7], dtype=int32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "\n",
    "# Create a new tensor with default datatype (int32)\n",
    "C = tf.constant([1, 7])\n",
    "B, C\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38c81ca-a947-4f3f-845f-72aed724e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Change from float32 to float16 (reduced precision)\n",
    "B = tf.cast(B, dtype=tf.float16)\n",
    "B\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78386a7-9cb1-450b-a536-30248edcfc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Change from int32 to float32\n",
    "C = tf.cast(C, dtype=tf.float32)\n",
    "C\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384e210-c8c7-4842-8763-fd74f5de76af",
   "metadata": {},
   "source": [
    "\n",
    "# Getting the absolute value\n",
    "Sometimes you'll want the absolute values (all values are positive) of elements in your tensors.\n",
    "\n",
    "To do so, you can use tf.abs()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7409de-9671-4667-a2aa-c0e4ccad851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create tensor with negative values\n",
    "D = tf.constant([-7, -10])\n",
    "D\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d386a3a6-a8cc-4a4e-a6d2-a095692a3e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b72f4-0e55-4713-8354-0d6ef21a1e09",
   "metadata": {},
   "source": [
    "# Finding the min, max, mean, sum (aggregation)\n",
    "You can quickly aggregate (perform a calculation on a whole tensor) tensors to find things like the minimum value, maximum value, mean and sum of all the elements.\n",
    "\n",
    "To do so, aggregation methods typically have the syntax reduce()_[action], such as:\n",
    "\n",
    "tf.reduce_min() - find the minimum value in a tensor.\n",
    "tf.reduce_max() - find the maximum value in a tensor (helpful for when you want to find the highest prediction probability).\n",
    "tf.reduce_mean() - find the mean of all elements in a tensor.\n",
    "tf.reduce_sum() - find the sum of all elements in a tensor.\n",
    "Note: typically, each of these is under the math module, e.g. tf.math.reduce_min() but you can use the alias tf.reduce_min().\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee904c50-fec6-4635-98fc-b4d581e09ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([ 5, 16, 68, 53, 44, 83, 57, 13, 53, 49, 74, 46, 79, 38, 51, 81, 42,\n",
       "       50, 61, 26, 59, 73, 15, 56, 22, 41, 69, 45, 33, 72, 42, 74, 35,  5,\n",
       "       11, 28, 37, 18, 73, 31, 13, 43, 53, 20, 78, 69, 37, 39, 60, 89],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create a tensor with 50 random values between 0 and 100\n",
    "E = tf.constant(np.random.randint(low=0, high=90, size=50))\n",
    "E\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68dc48f-d7f8-4a3c-9430-53976a709b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc597f7-516e-4454-9eca-d0e0a7009acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=89>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c1ca86-b9de-495b-8a8f-8bcf9ae196c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=46>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2890d81-9a9f-4950-abd6-74def22d153c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2329>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52841b9a-9568-43ac-8eb6-f466036d48c3",
   "metadata": {},
   "source": [
    "\n",
    "You can also find the standard deviation (tf.reduce_std()) and variance (tf.reduce_variance()) of elements in a tensor using similar methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e35de-f21b-45d2-a587-3e646d11e132",
   "metadata": {},
   "source": [
    "# Finding the positional maximum and minimum\n",
    "How about finding the position a tensor where the maximum value occurs?\n",
    "\n",
    "This is helpful when you want to line up your labels (say ['Green', 'Blue', 'Red']) with your prediction probabilities tensor (e.g. [0.98, 0.01, 0.01]).\n",
    "\n",
    "In this case, the predicted label (the one with the highest prediction probability) would be 'Green'.\n",
    "\n",
    "You can do the same for the minimum (if required) with the following:\n",
    "\n",
    "tf.argmax() - find the position of the maximum element in a given tensor.\n",
    "tf.argmin() - find the position of the minimum element in a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46602732-b46f-4e5c-bf90-ad0279eefaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.82719832, 0.41771832, 0.32165406, 0.84651263, 0.68966447,\n",
       "       0.60985153, 0.18746432, 0.6797282 , 0.57011034, 0.27598609,\n",
       "       0.77117529, 0.19614183, 0.17293703, 0.32117852, 0.19264101,\n",
       "       0.03522831, 0.39527063, 0.95933847, 0.63502679, 0.76817571,\n",
       "       0.52241758, 0.94343198, 0.83511706, 0.2920409 , 0.19655723,\n",
       "       0.49914655, 0.67522954, 0.82740812, 0.13644407, 0.91230633,\n",
       "       0.36776572, 0.60612981, 0.5357603 , 0.05515579, 0.53778178,\n",
       "       0.26039644, 0.6351498 , 0.94875205, 0.83772043, 0.08892708,\n",
       "       0.91029862, 0.28148981, 0.52711733, 0.64328121, 0.00576441,\n",
       "       0.71683409, 0.60933431, 0.46345219, 0.25225651, 0.31516729])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a tensor with 50 values between 0 and 1\n",
    "F = tf.constant(np.random.random(50))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bcfd6d-c996-45ee-b906-0897a68ff48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=17>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the maximum element position of F\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e33a32-7cd4-4f56-a458-6ce332d22d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=44>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the minimum element position of F\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a310ddf-0f3a-4b6b-8075-6f60d371c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value of F is at position: 17\n",
      "The maximum value of F is: 0.9593384696667685\n",
      "Using tf.argmax() to index F, the maximum value of F is: 0.9593384696667685\n",
      "Are the two max values the same (they should be)? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the maximum element position of F\n",
    "print(f\"The maximum value of F is at position: {tf.argmax(F).numpy()}\") \n",
    "print(f\"The maximum value of F is: {tf.reduce_max(F).numpy()}\") \n",
    "print(f\"Using tf.argmax() to index F, the maximum value of F is: {F[tf.argmax(F)].numpy()}\")\n",
    "print(f\"Are the two max values the same (they should be)? {F[tf.argmax(F)].numpy() == tf.reduce_max(F).numpy()}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd18f1-208c-4b55-bb66-720b95bcce71",
   "metadata": {},
   "source": [
    "\n",
    "# Squeezing a tensor (removing all single dimensions)\n",
    "If you need to remove single-dimensions from a tensor (dimensions with size 1), you can use tf.squeeze().\n",
    "\n",
    "tf.squeeze() - remove all dimensions of 1 from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93aecfda-b9c4-4eff-b571-64d1bff8537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=int32, numpy=\n",
       "array([[[[[59,  2, 36, 62, 81,  3, 44, 96, 60, 12,  6, 52, 32, 58, 54,\n",
       "           72, 70, 60, 89, 65, 59, 38, 81, 99, 82, 78, 17, 72,  9, 31,\n",
       "           50, 59, 43, 40,  6, 34, 95, 15, 74, 93, 90, 33, 32, 83,  7,\n",
       "           84, 21, 62, 28, 68]]]]], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a rank 5 (5 dimensions) tensor of 50 numbers between 0 and 100\n",
    "G = tf.constant(np.random.randint(0, 100, 50), shape=(1, 1, 1, 1, 50))\n",
    "G.shape, G.ndim\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c31dd9a0-6486-4e07-9181-5eed24b6e092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze tensor G (remove all 1 dimensions)\n",
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed.shape, G_squeezed.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59886483-8785-4453-bb82-7636cdb587b4",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "If you have a tensor of indicies and would like to one-hot encode it, you can use tf.one_hot().\n",
    "\n",
    "You should also specify the depth parameter (the level which you want to one-hot encode to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e2f28aa-bf69-4cf3-894f-670c03fcccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a list of indices\n",
    "some_list = [0, 1, 2, 3,4]\n",
    "\n",
    "# One hot encode them\n",
    "tf.one_hot(some_list, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99476e-18f8-498f-9105-d2ab54a1c5eb",
   "metadata": {},
   "source": [
    "You can also specify values for on_value and off_value instead of the default 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5c4e2be-2bb9-40a9-89ab-12ca7a44f486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=string, numpy=\n",
       "array([[b\"We're live!\", b'Busy', b'Busy', b'Busy'],\n",
       "       [b'Busy', b\"We're live!\", b'Busy', b'Busy'],\n",
       "       [b'Busy', b'Busy', b\"We're live!\", b'Busy'],\n",
       "       [b'Busy', b'Busy', b'Busy', b\"We're live!\"],\n",
       "       [b'Busy', b'Busy', b'Busy', b'Busy']], dtype=object)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Specify custom values for on and off encoding\n",
    "tf.one_hot(some_list, depth=4, on_value=\"We're live!\", off_value=\"Busy\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed13c79-323e-473d-9721-18605240c220",
   "metadata": {},
   "source": [
    "# Squaring, log, square root\n",
    "Many other common mathematical operations you'd like to perform at some stage, probably exist.\n",
    "\n",
    "Let's take a look at:\n",
    "\n",
    "tf.square() - get the square of every value in a tensor.\n",
    "tf.sqrt() - get the squareroot of every value in a tensor (note: the elements need to be floats or this will error).\n",
    "tf.math.log() - get the natural log of every value in a tensor (elements need to floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccb0905a-902d-4b48-8413-c471cdff14d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a new tensor\n",
    "H = tf.constant(np.arange(1, 10))\n",
    "H\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d9e0d17-9319-40c5-a4a4-660cf900b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Square it\n",
    "tf.square(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d95b4028-fa2a-4173-86df-8d52f7c306e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = tf.cast(H,dtype = tf.float32)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd5b3fd1-e01b-4092-a996-2dafbf3141c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.236068 , 2.4494898,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d58812f-476d-4116-b69c-357ab8118fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find the log (input also needs to be float)\n",
    "tf.math.log(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8881e0-1f80-48cf-ae69-5f0893b1580f",
   "metadata": {},
   "source": [
    "# Manipulating tf.Variable tensors\n",
    "Tensors created with tf.Variable() can be changed in place using methods such as:\n",
    "\n",
    ".assign() - assign a different value to a particular index of a variable tensor.\n",
    ".add_assign() - add to an existing value and reassign it at a particular index of a variable tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e19c3c16-42bf-4069-997b-a4bb3708f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([0, 1, 2, 3, 4])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a variable tensor\n",
    "I = tf.Variable(np.arange(0, 5))\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287a910d-0329-420a-a0af-0a997eca281a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int64, numpy=array([ 0,  1,  2,  3, 50])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assign the final value a new value of 50\n",
    "I.assign([0, 1, 2, 3, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f300b889-c7b1-4f37-b871-6a43235a48b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([ 0,  1,  2,  3, 50])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The change happens in place (the last value is now 50, not 4)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf5b5f83-dfc0-4145-8142-ddafe8e97bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int64, numpy=array([100, 181, 412, 313, 260])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Add 10 to every element in I\n",
    "I.assign_add([100, 180, 410, 310, 210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cacdaffb-992d-4ca0-9396-0a0610c44670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5,) dtype=int64, numpy=array([100, 181, 412, 313, 260])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Again, the change happens in place\n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7658021-320b-454b-89ea-d33b8c383d97",
   "metadata": {},
   "source": [
    "# Tensors and NumPy\n",
    "We've seen some examples of tensors interact with NumPy arrays, such as, using NumPy arrays to create tensors.\n",
    "\n",
    "Tensors can also be converted to NumPy arrays using:\n",
    "\n",
    "np.array() - pass a tensor to convert to an ndarray (NumPy's main datatype).\n",
    "tensor.numpy() - call on a tensor to convert to an ndarray.\n",
    "Doing this is helpful as it makes tensors iterable as well as allows us to use any of NumPy's methods on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7575f35f-a9ab-477b-9c59-3bff71da90f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a NumPy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ef3c4d1-3abe-42d9-a423-b53a86c7ebaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert tensor J to NumPy with np.array()\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42e79fa6-21a4-4106-a7e9-454fd35f9f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert tensor J to NumPy with .numpy()\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a61379-4d06-4921-91e6-26a76365b5bc",
   "metadata": {},
   "source": [
    "By default tensors have dtype=float32, where as NumPy arrays have dtype=float64.\n",
    "\n",
    "This is because neural networks (which are usually built with TensorFlow) can generally work very well with less precision (32-bit rather than 64-bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3d6e2a0-8774-4c21-a030-1d27d6c1c96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a tensor from NumPy and from an array\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.])) # will be float64 (due to NumPy)\n",
    "tensor_J = tf.constant([3., 7., 10.]) # will be float32 (due to being TensorFlow default)\n",
    "numpy_J.dtype, tensor_J.dtype\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9c65e-d811-4a27-b8b9-9f8e6247bb35",
   "metadata": {},
   "source": [
    "# Using @tf.function\n",
    "In your TensorFlow adventures, you might come across Python functions which have the decorator @tf.function.\n",
    "\n",
    "If you aren't sure what Python decorators do, read RealPython's guide on them.\n",
    "\n",
    "But in short, decorators modify a function in one way or another.\n",
    "\n",
    "In the @tf.function decorator case, it turns a Python function into a callable TensorFlow graph. Which is a fancy way of saying, if you've written your own Python function, and you decorate it with @tf.function, when you export your code (to potentially run on another device), TensorFlow will attempt to convert it into a fast(er) version of itself (by making it part of a computation graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dab2a18-5079-47d6-95cf-9070943f8cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=\n",
       "array([   10,    12,    44,   256,  1038,  3140,  7792, 16824, 32786,\n",
       "       59068])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a simple function\n",
    "def function(x, y):\n",
    "  return x ** 5 + y\n",
    "\n",
    "x = tf.constant(np.arange(0, 10))\n",
    "y = tf.constant(np.arange(10, 20))\n",
    "function(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "161f8199-f8fb-4a38-9dff-44b0a9cbc884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=\n",
       "array([   10,    12,    44,   256,  1038,  3140,  7792, 16824, 32786,\n",
       "       59068])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the same function and decorate it with tf.function\n",
    "@tf.function\n",
    "def tf_function(x, y):\n",
    "  return x ** 5 + y\n",
    "tf_function(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5b64b-7263-4fd9-8166-9ea80c87b84e",
   "metadata": {},
   "source": [
    "\n",
    "If you noticed no difference between the above two functions (the decorated one and the non-decorated one) you'd be right.\n",
    "\n",
    "Much of the difference happens behind the scenes. One of the main ones being potential code speed-ups where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf914ddb-1dd2-476e-ae38-5b157fa73021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf310)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
